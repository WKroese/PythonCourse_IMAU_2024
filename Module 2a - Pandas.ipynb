{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 2: importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of this tutorial is based on the user guides of pandas (https://pandas.pydata.org/docs/user_guide/index.html), netcdf4 (https://unidata.github.io/netcdf4-python/) and xarray (http://xarray.pydata.org/en/stable/user-guide/index.html). Also, part of this tutorial is based on the Python introduction from last years of André Jüling, created under the BSD 3-Clause License (https://github.com/AJueling/python_climate_physics), and Janneke Krabbendam.\n",
    "\n",
    "There are many different types of datafiles and there are a lot of Python tools available to deal with these data. Datacamp has provided a [cheatsheet](http://datacamp-community-prod.s3.amazonaws.com/72e88aa1-b4f2-4658-9d86-15becf8263df) with a nice overview of what package to use for what types of data. Most of the time, you will able to use the tools in NumPy, especially if you have .txt or .csv files. But in this tutorial, we will introduce you to new libraries that are really useful: [pandas](https://pandas.pydata.org/docs/user_guide/index.html), [NetCDF4](https://unidata.github.io/netcdf4-python/) and [xarray](http://xarray.pydata.org/en/stable/user-guide/index.html). \n",
    "\n",
    "- __Pandas__ = library for importing, processing and analysing tabular data, such as spreadsheets.\n",
    "- __NetCDF4__ =  lower level interface for working with netCDF and OpenDAP datasets, you can read and modify files on-disk.\n",
    "- __xarray__ = for multidimensional data processing. It builds on NetCDF4 and NumPy and has a lot of useful tools for dataprocessing. It is similar to Pandas, but then for NetCDF files.\n",
    "\n",
    "All of these libraries are open-source. You probably will notice that this tutorial is leaning heavily towards NetCDF files. This was on purpose, as during the master, you will often come across these type of files as this is a very efficient way to store large datasets/model output!\n",
    "\n",
    "# a) Pandas\n",
    "\n",
    "The first part of the tutorial will focus on working with Pandas, the second part on NetCDF4 and xarray. First, let's import the package\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "You can check wether pandas is alreay installed on your pc with the command\n",
    "\n",
    "`conda list`\n",
    "\n",
    "This gives an overview of all the packages that are installed. If you don't have pandas yet, install it with\n",
    "\n",
    "`conda install pandas` or `pip install pandas` \n",
    "\n",
    "You can do this directly in the Notebook or in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Structures: Series\n",
    "\n",
    "A __Series__ represents a one-dimensional, labelled array of data. This array can hold any type of data (integers, strings, floats, Python objects, ...). The label is called an __index__, this the main difference between a Series and NumPy array. We can access the data through this index.\n",
    "\n",
    "There are many ways to [create a Series](https://pandas.pydata.org/pandas-docs/stable/dsintro.html#series). We will just show a few.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Alice', 'Bob', 'Claire']\n",
    "values = [30, 15, 22]\n",
    "ages = pd.Series(values, index=names)\n",
    "ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, the names are the __index__. We can access the underlying index object if we need to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic operations and most NumPy function can be applied to Series.\n",
    "An important point is that the Series keep their index during such operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(ages) / ages**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series have built in plotting methods, such as line plots, bar plots, histograms and many more (see https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html). In order to access these options, you need to import matplotlib (which we already did)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "We can get values back out using the index via the `.loc` attribute. Or by raw position using `.iloc`, raw positioning is the numbered, zero-based indexing that we have seen before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ages.loc['Alice'])\n",
    "print(ages.iloc[0])\n",
    "print(ages.loc['Claire'])\n",
    "print(ages.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to, we can always get the raw data back out as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.values # a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Structures: DataFrame\n",
    "\n",
    "There is a lot more to Series, but they are limited to a single \"column\". A more useful Pandas data structure is the __DataFrame__, which is a 2D data structure.  A DataFrame is basically a bunch of series that share the same index. It's a lot like a table in a spreadsheet. A DataFrame can handle all sorts of data, such as n-dimensional ndarrays, lists and Series. Along with the data, you can again optionally pass __index__ (row labels) and __columns__ (column labels) arguments. \n",
    "\n",
    "Below we create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create a dictionary\n",
    "data = {'age': [30, 15, 22],\n",
    "        'height': [180, 155, 160],\n",
    "        'weight': [70, 52, np.nan]}\n",
    "df = pd.DataFrame(data, index=['Alice', 'Bob', 'Claire'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily get information about a DataFrame with the command `pd.info()`. This tells you the size of the DataFrame, the type of data is in there and how much memory it uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above, you see `NaN`. This means 'not a number' and represents missing data. When dealing with real data, often you have to deal with this. Pandas handles missing data very elegantly, keeping track of it through all calculations. To easily locate missing data, you can use the commands `pd.isna()` and `pd.notna()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(df['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notna(df['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that these commands give a Boolean result which tell you where the `NaN`s are.\n",
    "\n",
    "A wide range of statistical functions are available on both Series and DataFrames. You will see that if you don't specify over what index/column you want to apply this function, these functions return the output per index. You can also see that these functions still work even though we have missing data. We show some examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min() # minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std() # standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful command is `describe`, this provides an overview of some basic statics of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Indexing for DataFrames is very similar to Series (`loc` and `iloc`). We can also get a single column as a Series using Python's getitem syntax on the DataFrame object or by using the attribute syntax (examples given below). Note that we are now dealing with 2D data, so if you want to get one singular entry, you need to specify both the row and the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'] # getitem syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.height # attribute syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Bob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Claire', 'age'] # to get one entry, specify the index(=row) and the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2, 0] # or with 'normal' zero-based indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations\n",
    "\n",
    "We can make a calculation using columns from the DataFrame, it will keep the same index. We can easily add  these as another column to the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BMI'] = df.weight / (df.height/100)**2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also index using a Boolean series. This is very useful to extract certain portions of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_adult'] = df.age > 18\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Like we saw with Series, DataFrames have all kinds of [useful plotting](https://pandas.pydata.org/pandas-docs/stable/visualization.html) built in. We will go through some examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='age', y='height', grid=True, s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Indexes\n",
    "\n",
    "Indexes are very powerful. They are a big part of why Pandas is so useful. There are different indices for different types of data. Time Indexes are especially great! In the following example, we will create a time array with the command `pd.date_range` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_years = pd.date_range(start='2014-01-01', end='2016-01-01', freq='D')\n",
    "two_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = pd.Series(np.sin(2 *np.pi *two_years.dayofyear / 365),\n",
    "                       index=two_years)\n",
    "timeseries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had specified the full date, but you can for example also get certain parts of these times in days with the command `timeseries.index.dayofyear`, or the month with `timeseries.index.month` or the day in the month with `timeseries.index.day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timeseries.index.dayofyear,timeseries.index.month,timeseries.index.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use python's slicing notation inside `.loc` to select a date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries.loc['2015-01-01':'2015-07-01'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data Files: Weather Station Data\n",
    "\n",
    "In this example, we will use weather station data from the [National Center of Environmental Information from the NOAA](https://www.ncei.noaa.gov/access/search/dataset-search?observationTypes=Land%20Surface). Here, you can find a lot of data and model output freely available. The [data](https://github.com/JannekeKrabbendam93/Python-Climate-Physics-2021/blob/main/sample.csv) used here are part of the Global Summary of the Day and they are measured at the airport in Denver (USA) in 2018. The accompanying [ReadMe file](https://github.com/JannekeKrabbendam93/Python-Climate-Physics-2021/blob/main/README.txt) gives a description of the data, for example the units that the data are in. I have already downloaded the data for you and uploaded it on and Blackboard.\n",
    "\n",
    "If you download that file, you now have a csv file on our hard drive called `sample.csv`. Examine it.\n",
    "\n",
    "To read it into Pandas, we will use the [read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function. This function is incredibly complex and powerful. You can use it to extract data from almost any text file. However, you need to understand how to use its various options.\n",
    "\n",
    "Before you load this file into Python, make sure that either the datafile is in the same folder as your notebook, or provide the notebook with a path to the datafile. I put the file in a folder called `data`, this folder is located in the same folder as the notebook, so the path to the data is `data/sample.csv`.\n",
    "\n",
    "With no options, this is what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that Pandas immediately is able to recognise the headers and the different columns. This is because in our file, the columns are separated by a comma, like expected. If you would try to read a different text file, where the columns are separated in a different way, you can tell pandas this by using the keyword `sep`.\n",
    "\n",
    "If we look closely, we will see there are lots of 999.9 and 99.99 values in the file. The README tells us that these are values used to represent missing data. Let's tell this to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sample.csv', sep=',', na_values=[9999.9, 999.9, 99.99])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. The missing data is now represented by `NaN`.\n",
    "\n",
    "What data types did pandas infer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem here is that pandas did not recognize the `DATE` column as a date. Let's help it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sample.csv', sep=',', na_values=[9999.9, 999.9, 99.99], parse_dates=[1])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Finally, let's tell pandas to use the date column as the index with `set_index`. This way we can access all the values by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('DATE')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can easily get all the measurements at one single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['07/08/2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use slicing to get a range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['01/07/2018':'31/07/2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick statistics\n",
    "\n",
    "With the commmand `describe` we can get some quick statistics. Which columns have we skipped here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,4:].describe() # start from the 5th column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Values\n",
    "\n",
    "We can now quickly make plots of the data. Boxplots can give a very good idea of the spread in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(8,8), constrained_layout=True)\n",
    "\n",
    "ax[0,0].set_title('temperature')\n",
    "df.iloc[:, [5,7,19,21]].boxplot(ax=ax[0,0])\n",
    "ax[0,1].set_title('pressure')\n",
    "df.iloc[:, [9,11]].boxplot(ax=ax[0,1])\n",
    "ax[1,0].set_title('precipitation')\n",
    "df.iloc[:, [23,25]].boxplot(ax=ax[1,0])\n",
    "ax[1,1].set_title('wind')\n",
    "df.iloc[:, [15,17,18]].boxplot(ax=ax[1,1])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].set_xticklabels(ax[i,j].get_xticklabels(), rotation=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is very \"time aware\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEMP.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we could also manually create an axis and plot into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df.TEMP.plot(ax=ax)\n",
    "ax.set_title('Pandas Made This!')\n",
    "ax.set_ylabel('T (Fahrenheit)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_list = ['MIN', 'TEMP', 'MAX']\n",
    "df[temps_list].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling operations\n",
    "\n",
    "We easily calculate the running mean by applying a [rolling](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html) window and specifying a function (in this case the `mean` function) to apply over a moving window along the index. We specify the size of the window and, optionally, the weights. We also use the keyword `centered` to tell pandas whether to center the operation around the midpoint of the window.\n",
    "\n",
    "In the following example, we get the 30-day moving average temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[temps_list].rolling(30, center=True).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercises</span>\n",
    "1. Convert the following dictionary into a Pandas Series and display on overview of basic statistics (count, mean, std, min,... see DataFrame subsection above). `d1 = {'a': 100, 'b': 200, 'c':300, 'd':400, 'e':800}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the following data into a DataFrame:\n",
    "```\n",
    "exam_data={'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "              'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "              'attempts' : [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "              'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "```\n",
    "Calculate the mean score, select those whose attemps>2, and calculate how many rows are missing a score (you can use the built-in `.isnull()` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a a daily time series from 2015-2020 with an noisy annual cycle. Resample the data by taking the mean over each month using `resample('M')`. Create the climatology (monhtly means) using the groupby(timeseries.index.month) operator.\n",
    "<img src=\"figures/3a3.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
